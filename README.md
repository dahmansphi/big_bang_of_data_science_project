> [!IMPORTANT] 
> make sure to check the book [competitive advantages](#what-is-the-competitive-advantage) below. 

> [!NOTE]
> 1. to visit the musical introduction for the first edition check [Musical Introduction](https://youtu.be/px5kgI4Nrxc).
> 2. to learn about Dahman's Phi Services initiative please see [Dahman's Phi Services Initiative](https://youtu.be/LbJAsCSf6Zw)

![the big bang of data science banner.](/assets/cover_page.jpg)
# About the Project
## Author's Words
Welcome to **The Big Bang of Data Science** official documentation. I am Dr. Deniz Dahman 
the creator of the [BireyselValue algorithm](https://github.com/dahmansphi/bireyselvalue_v1/tree/main) and the author of this digital book. In the following section you  
will have a brief introduction on the principal idea of the Big Bang of Data Science.  
In addition, a reference to available outlets where you may have access to the entire recorded lessons.  
Before going ahead, I would like to let you know that I have done this project as an independent scientist without any fund or similar capacity.  
I am dedicated to proceeding and seek further improvement of the content of this material.  
To this end if you wish to contribute in any way to this work, please find further details in the contributing section.  
  
## Contributing 

If you wish to contribute to the creator of this method and the author, you may want to check possible ways on: 

> `To Contribute in any way possible, thank you, you can check` :

1. view options to subscribe on [Dahman's Phi Services Website](https://dahmansphi.com/subscriptions/)
2. subscribe to this channel [Dahman's Phi Services](https://www.youtube.com/@dahmansphi)     
3. you can support on [patreon](https://patreon.com/user?u=118924481) 


If you prefer *any other way of contribution*, please feel free to contact me directly on [contact](https://dahmansphi.com/contact/). 

*Thank you*

# The Big Bang of Data Science -first edition- at a glance

## the four elements

> [!NOTE]
> To have a video presentaion on this section please visit [Main Introduction to The Big Bang of Data Science- First Edition](https://youtu.be/0weCBnNO7tk).


A **product**, as a simple definition, is _the outcome of some kind of input that has been processed and as a result 
you have the outcome of that as a product_. Well, that sounds academic, however the fact is much deeper than few vocabs. 
Let me explain what I mean, a student who plans to enroll at a university, doesn’t just pick and here we go! 
It must have been quite a few steps towards that. Essentially, student might have decided on his/her league, i.e. 
are they working on rigid establishment institutions, or soft one. Either way, once he/she knows, then next, will 
be to prepare what is needed. That could be working on certain scores, perhaps on specific project requirements, 
or maybe financial arrangements, etc. So, **the input** is what is needed to be enrolled, **the process** is what student 
does to orchestrate that, and finally, **the outcome** is the student enrolment at the university. So, this _eventual  status_, 
a university student, is **a product**. Let's take a second example, someone plans to buy a house, just like the 
student story, he/she must work out on their budgets, market values, etc., and finally, process all that to make 
the best choice that fits in, the result, a house owner. This status is a product. Alright, _let’s be more technical_,
company *X* plans to introduce a new digital/physical product. Of course, teamwork starts to collect the information 
about the product, work on the required raw materials, etc. Then process all of which to outcome that. The result, 
a social media software app, or a new device in the market. You have got the point.    

![the three principles of a product.](/assets/input_process_output.gif)

Now if we put it all together and use synonymous vocabularies, we easily can find that, everything starts with NEED, 
i.e. problem, which is going to be the block to put all what you have as an **INPUT**. Next, you should realize that 
what you have is the name of **DATA**. And data is meant, _by the law of nature_, to be processed. That is exactly the 
second step. Finally, you are going to outcome a solution, or what I have named as a **PRODUCT**.  

So, the question is now, _what do you really need to know to orchestrate these three steps in order?_ Here is what I believe: 
> [**Research mastery**], you must know how to conduct **research** _from the start to the end_. That includes, and is not 
limited to, skills of articulating your research question, conducting the research framework, defining space of 
variables, creating instrument to measure those variables, collecting, storing data which have been measured, 
and so on. 
 
> [**Analysis mastery**], now is time of truth. In this step you start to do **analysis** _from the start to the end_ on 
the data that you have. You find patterns, hidden structures, you tabulate, graph and so on. Finally, you have answers 
to your research question. That is the output, the product, the solution.  

Here we go! But wait a second, it’s legitimate to think, this solution/product you have just outcome, has only two embedded elements (1) **PAST**, (2) **PRESENT**. You have these past data, and you did the present process, so _what is missing?_ The obvious answer is the **FUTURE**. You need future element to be present in the profile of your solution/product.  

> [**Prediction mastery**], this is where the _future_ can be present in your solution/product. Prediction is telling you an educated guess about the future. It tells you based on your _past and present_, what is probole outcome of future. That means, your solution will have a new adjective added to it, that is **intelligent**, or smart solution/product.  

So, now let’s conclude all what we have examined. (1) **RESEARCH from the start to the end**, (2) **ANALYSIS from the start to the end** (3) **PREDICTION from the start to the end**. Are the real blocks to outcome intelligent solution or product. 
**`and these are the first three elements of the Big Bang of Data Science, in the form of three books`**

Great, so now we have this solution, logically speaking, in the form of a model or a framework and what we can do with it. Simply put, we can **turn it into** a form of **a digital or physical product**. For instance, we can create a **GUI** that the user can _interacts_ with or maybe **a device** that the user can _use_. Now, this is **`the fourth element of the BIG BANG OF DATA SCIENCE`**, in the form of book, (4) **CODE AI from the start to the end**. 

**``So, here I introduce the first edition of the Big Bang of Data Science. Which includes four books' elements as below:``**


- [x] [Rsearch From the Start to the End](https://github.com/dahmansphi/research_from_start_to_end), 
- [x] [Analysis From the Start to the End](https://github.com/dahmansphi/analysis_from_start_to_end) 
- [x] [Prediction From the Start to the End](https://github.com/dahmansphi/prediction_from_start_to_end),
- [x] [Code AI From the Start to the End](https://github.com/dahmansphi/code_ai_from_start_to_end),  

## WHAT IS THE COMPETITIVE ADVANTAGE?
Today’s online educational stores are flooded with immense number of materials covering the contents of each element as presented above. However, most of the time there is **this missing** connection between them, for instance, **on the crucial value importance of research**. See, many would suggest the **claim** that `data is the main input for a prediction model, that’s why it needs first to be cleaned and processed before shipping to the prediction block`. That’s _right in some ways_, and _wrong in other ways_. Let me explain, without data I can make no prediction, that’s right. So, the previous claim then is right. **However**, where the data comes from! The source of _the data is the process of research_. So, if you would have from the very beginning **a wrong research foundation**, then no matter what advanced, and classy tools you have used to clean the data will never make a difference. See, you may, at face value, pre-process and clean the data, and the result would look just fine, then you feed that into the prediction blook, and you do the prediction. But you will always suffer the painful fact of UNEXPECTED results, **wrong prediction**, etc. That happened actually, because of **the wrong foundation of research**.  

To this end, **the big bang of data science** is _very carefully crafted material_ that **addresses this matter** in principle. `It takes you on a journey to build and create your final product/solution based on the right research foundation`. So, essentially, it shows you how to build scientific research framework, then how to work on the right methods of analysis, and finally, how to use that analytical model as an input for the prediction. _In addition_, in this **first addition**, it illustrates a way to turn that product into a digital one, using a GUI for the user to interact with, in the form of a desktop solution.  

`What you find here is a mimic of a path` **`from Academia to Industry`**, from the start to the end.    

![the research foundation framework.](/assets/researh_foundation.gif)

`But more important` **`this path is constructed based on the nature number of phi proportion of measurements`**, from the start to the end. 
 
 ![Phi is the logo of Dahman's initiative](/assets/phi_meaning.png)

# The Big Bang of Data Science- SECOND EDITION

> [!NOTE]
> To have a video presentaion on this section please visit [Main Introduction to The Big Bang of Data Science- Second Edition](https://youtu.be/_DZpqfy0I34).

If you have made the decision to complete the first edition of **the Big Bang of Data Science**, then you may want to learn about its vision in the second Edition. _The second edition of the Big Bang of Data Science_ is going to cover **two** important areas of disciplines as follows:  
## Embedding Systems- Software Engineering 
As the first edition has made its focus to outcome a product of _past-present-future_, that is in form of a smart/intelligent model, we saw the fourth element was to turn that model into sort of a _GUI, desktop app_. However, in the second edition, the aim is **to embed that model into a device**, yet to make the device sound intelligent. So, we are going to focus on the skills that enable us to do so. Here are number of the outlines which will be at the center of attention: 

1. C Programming Language  
2. Basic Electronics 
3. Working on microcontrollers Arduino 
4. Working on industrial light weight microcontrollers, SMT32  

## Quantum Computing  

In the second focus, we are going to cover abstract and theoretical knowledge about **quantum computing**. The new phenomenon that everyone is talking about. Since the traditional computers framework is based on analog and digital forms of 1 and 0, quantum computing has a completely different framework. To this, if this frame excels soon, then _the entire industry will have this new framework_, which **will change** the way we write codes and interact with machines. I will be focusing on the abstract of it, since there are yet no available quantum machines in the market, but only available for R&D purposes. However, I will cover the outlines that make one able to master the work if it is released anytime soon on the market.  

1. Mathemetics- Probability theory 
2. Physics 
3. Computer Science 
4. Molecular Physics 
5. Chemistry 
